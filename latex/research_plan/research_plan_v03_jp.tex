\documentclass[twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}  % 调整页面边距
\usepackage{titling}               % 控制标题位置
\usepackage{booktabs}              % 表格宏包
\usepackage{amssymb}
\usepackage{ctex}                  % 中文支持包
\usepackage{authblk}			   % 多作者
\usepackage{graphicx}
\usepackage{ragged2e}           % 摘要两端对齐
% \usepackage{tabularx}			% 表格宽度
% \usepackage{xeCJK}
\setlength{\droptitle}{-3.0cm}     % 将标题上移3.0厘米

\title{PET-to-CT画像生成のための輝度感受性カスケード生成ネットワークに関する研究計画}
\author[1] {Xiaoyu Deng}
% \author[1,2] {Kouki Nagamune}
% \author[1] {Hiroki Takada}
% \author[1] {Teacher Author}
% \author[1,3]{Third Author}
\affil[1]{University of Fukui, 3-9-1 Bunkyo, Fukui, 910-0017, Japan}
% \affil[2]{University of Hyogo, 2167 Shosha, Himeji, Hyogo, 670-2280, Japan}
% \affil[3]{Research Institute, Company Z}
\date{ }

\begin{document}

\twocolumn[
	\maketitle

	% 	\begin{center}
	% 		\begin{abstract}
	% 			\begin{justify}
	% 				% U-Net, a widely recognized deep learning architecture, excels in medical image processing tasks due to its symmetric encoder-decoder structure and skip connections, effectively preserving spatial information critical for precise segmentation. Although enlarging U-Net through depth increments, additional channels, improved skip connections, or integrating attention mechanisms such as Transformers can boost performance, it also introduces computational complexity and performance bottlenecks.

	% 				% This study proposes a multi-stage cascaded framework utilizing sequentially connected simple encoder-decoder modules for the CT-to-PET medical image translation task, preserving simplicity within each encoder-decoder structure. The effectiveness of the framework is validated experimentally using publicly available lung cancer PET-CT datasets, assessing performance across various stages. Metrics including SSIM, PSNR, and MAE demonstrate significant improvements in image reconstruction quality, particularly at higher cascade stages, achieving peak SSIM of 0.9255 and PSNR of 28.9168 dB.

	% 				% Visual comparison further indicates that despite high quantitative metric scores, certain visual artifacts remain due to transposed convolution operations, suggesting that pixel-level metrics alone may not comprehensively reflect perceptual quality. The proposed multi-stage cascaded U-Net model, therefore, presents strong potential for medical imaging applications, particularly in synthesizing high-quality PET images from CT scans, with recommendations for future integration of visual quality assessments and expert evaluations.
	% 			\end{justify}
	% 		\end{abstract}
	% 	\end{center}
	% 	\vspace{0.5cm}  % 调整摘要与正文之间的间距
]

\section{研究背景}
正電子放射断層撮影（PET）およびコンピュータ断層撮影（CT）は、それぞれ代謝情報と解剖情報を提供する。PET/CT装置は一度の撮影で両方の情報を同時に取得できるが、装置の価格が高く、被曝線量も比較的多いため、資源の限られた環境では普及が難しい。近年、生成敵対ネットワーク（GAN）\cite{radford_unsupervised_2015} は医用画像のモーダル間変換において大きな可能性を示している。しかし、従来手法にはテクスチャのぼやけ、高輝度領域での強度歪み、性能の頭打ちなどの問題が残されている。これらの課題に対処するため、本研究ではカスケード型エンコーダ・デコーダ拡張フレームワークと輝度感受性損失を統合した\emph{輝度感受性カスケードGAN}を提案し、CT画像からPET画像への合成精度を向上させる。本研究では、多段階生成および輝度適応制約が臨床的に有用な疑似PET画像生成にどのように寄与するかを体系的に検証し、低コストでの早期診断の技術基盤を提供することを目指す。

\section{研究目的}
\textbf{理論的目的：} 解釈可能なクロスモーダル・カスケード生成フレームワークを構築し、多段階分解および輝度感受性損失が画像の構造およびテクスチャ再現性をどのように改善するかを解明する。

\textbf{アルゴリズム的目的：} 多段階生成器、マルチスケール輝度モデリング、適応的重みスケジューリング戦略を設計・最適化し、高輝度および低輝度領域の詳細再現性能を向上させる。

\textbf{応用的目的：} 複数施設の公開および臨床脳PET/CTデータセットを用いてモデルの頑健性と転移可能性を検証し、早期脳卒中スクリーニング、腫瘍の定量化、アルツハイマー病前駆期の検出支援への有用性を評価する。

\section{研究方法}
\subsection{使用データセット}
本研究では、米国国立がん研究所（NCI）の癌画像プログラム（CIP）\cite{li_large-scale_2020} による肺PET/CTデータセットを利用する。このデータセットは355名の患者から収集された合計251,135枚のDICOM画像と、性別、年齢、体重、喫煙歴、診断カテゴリーなどのメタデータを含む。腫瘍のサブタイプは、腺癌（A）、小細胞癌（B）、大細胞癌（E）、扁平上皮癌（G）に分類されている。本研究では、両モダリティを備えた患者群のうち、B型小細胞癌患者38名を選択し、造影画像を含めて計464対のPET/CT画像ペアを解析対象とする。データは全て匿名化され、RGB $256\times256$画素に再サンプリングされる。

\subsection{手法の最適化}
既存手法の限界を克服するため、より効率的なネットワーク構造および学習戦略を検討する。
\begin{enumerate}
	\item DSGGAN\cite{wang_dsg-gandual-stage-generator-based_2024} やU-Net\cite{navab_u-net_2015} などの手法をベースに、医用画像変換に特化した生成器・識別器を設計する。
	\item カスケード拡張フレームワークおよび注意機構を導入し、重要な解剖構造にフォーカスした変換を促す。
	\item 知覚損失と敵対的損失を融合した複合損失関数を検討し、視覚的リアリズムおよび構造的類似度を向上させる。
	\item マルチタスクおよび転移学習を採用し、モデルの汎化性能および収束速度を向上させる。
\end{enumerate}

\section{研究の革新性}
\begin{enumerate}
	\item \textbf{多段階拡張学習性の段階的評価：} カスケード型生成器の特性を詳細に解析し、無計画な積層による過学習を抑えつつ、その利点を最大限に引き出す。
	\item \textbf{マルチスケール輝度感受性機能：} 適応重みを持つ輝度マスクを導入し、高密度皮質骨および低密度実質テクスチャの双方を効果的に再現する。
\end{enumerate}

\section{期待される成果}
\textbf{アルゴリズム的成果：} 輝度感受性カスケードGANの高性能フレームワークおよび再現性の高いデータ前処理パイプラインの確立。

\textbf{学術的成果：} \emph{JACIII} や \emph{IEEE TMI} 等の査読付き学術誌への論文投稿を最低2本行う、あるいは日本で特許を1件出願する。





% \section*{Acknowledage}
% We would like to express our sincere gratitude to the National Cancer Institute Cancer Imaging Program for generously making their high-quality medical imaging dataset available and authorized for use on the Internet, providing indispensable resources for the smooth conduct of this research.

\bibliographystyle{unsrt}
\bibliography{rp_ref}

\end{document}
