@misc{li_large-scale_2020,
	title = {A {Large}-{Scale} {CT} and {PET}/{CT} {Dataset} for {Lung} {Cancer} {Diagnosis}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://www.cancerimagingarchive.net/collection/lung-pet-ct-dx/},
	doi = {10.7937/TCIA.2020.NNC2-0461},
	abstract = {This dataset consists of CT and PET-CT DICOM images of lung cancer subjects with XML Annotation files that indicate tumor location with bounding boxes. The images were retrospectively acquired from patients with suspicion of lung cancer, and who underwent standard-of-care lung biopsy and PET/CT. Subjects were grouped according to a tissue histopathological diagnosis. Patients with Names/IDs containing the letter 'A' were diagnosed with Adenocarcinoma, 'B' with Small Cell Carcinoma, 'C' with Large Cell Carcinoma, and 'G' with Squamous Cell Carcinoma.},
	urldate = {2024-10-18},
	publisher = {The Cancer Imaging Archive},
	author = {Li, Ping and Wang, Shuo and Li, Tang and Lu, Jingfeng and HuangFu, Yunxin and Wang, Dongxue},
	year = {2020},
}

@inproceedings{zeng_swin-casunet_2022,
	address = {Montreal, QC, Canada},
	title = {Swin-{CasUNet}: {Cascaded} {U}-{Net} with {Swin} {Transformer} for {Masked} {Face} {Restoration}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-062-7},
	shorttitle = {Swin-{CasUNet}},
	url = {https://ieeexplore.ieee.org/document/9956183/},
	doi = {10.1109/ICPR56361.2022.9956183},
	urldate = {2024-08-28},
	booktitle = {2022 26th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Zeng, Chengbin and Liu, Yi and Song, Chunli},
	month = aug,
	year = {2022},
	pages = {386--392},
}

@article{singh_automated_2023,
	title = {Automated nonlinear registration of coronary {PET} to {CT} angiography using pseudo-{CT} generated from {PET} with generative adversarial networks},
	volume = {30},
	issn = {10713581},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071358123001447},
	doi = {10.1007/s12350-022-03010-8},
	language = {en},
	number = {2},
	urldate = {2024-08-28},
	journal = {Journal of Nuclear Cardiology},
	author = {Singh, Ananya and Kwiecinski, Jacek and Cadet, Sebastien and Killekar, Aditya and Tzolos, Evangelos and Williams, Michelle C and Dweck, Marc R. and Newby, David E. and Dey, Damini and Slomka, Piotr J.},
	month = apr,
	year = {2023},
	pages = {604--615},
	file = {PubMed Central Full Text PDF:C\:\\Users\\ClannXy\\Zotero\\storage\\UYU5P3F9\\Singh 等 - 2023 - Automated nonlinear registration of coronary PET to CT angiography using pseudo-CT generated from PE.pdf:application/pdf},
}

@article{dong_synthetic_2019,
	title = {Synthetic {CT} generation from non-attenuation corrected {PET} images for whole-body {PET} imaging},
	volume = {64},
	issn = {1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/ab4eb7},
	doi = {10.1088/1361-6560/ab4eb7},
	number = {21},
	urldate = {2024-08-28},
	journal = {Physics in Medicine \& Biology},
	author = {Dong, Xue and Wang, Tonghe and Lei, Yang and Higgins, Kristin and Liu, Tian and Curran, Walter J and Mao, Hui and Nye, Jonathon A and Yang, Xiaofeng},
	month = nov,
	year = {2019},
	pages = {215016},
	file = {PubMed Central Full Text PDF:C\:\\Users\\ClannXy\\Zotero\\storage\\PIZBI9XZ\\Dong 等 - 2019 - Synthetic CT generation from non-attenuation corrected PET images for whole-body PET imaging.pdf:application/pdf},
}

@article{liu_deep_2018,
	title = {A deep learning approach for {18F}-{FDG} {PET} attenuation correction},
	volume = {5},
	issn = {2197-7364},
	url = {https://ejnmmiphys.springeropen.com/articles/10.1186/s40658-018-0225-8},
	doi = {10.1186/s40658-018-0225-8},
	language = {en},
	number = {1},
	urldate = {2024-08-28},
	journal = {EJNMMI Physics},
	author = {Liu, Fang and Jang, Hyungseok and Kijowski, Richard and Zhao, Gengyan and Bradshaw, Tyler and McMillan, Alan B.},
	month = dec,
	year = {2018},
	pages = {24},
	file = {全文:C\:\\Users\\ClannXy\\Zotero\\storage\\RG93XQJK\\Liu 等 - 2018 - A deep learning approach for 18F-FDG PET attenuation correction.pdf:application/pdf},
}

@inproceedings{zhu_unpaired_2017,
	address = {Venice},
	title = {Unpaired {Image}-to-{Image} {Translation} {Using} {Cycle}-{Consistent} {Adversarial} {Networks}},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237506/},
	doi = {10.1109/ICCV.2017.244},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to push F (G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transﬁguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	language = {en},
	urldate = {2024-08-28},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = oct,
	year = {2017},
	pages = {2242--2251},
	file = {PDF:C\:\\Users\\ClannXy\\Zotero\\storage\\MHMND3JL\\Zhu 等 - 2017 - Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks.pdf:application/pdf},
}

@inproceedings{isola_image--image_2017,
	address = {Honolulu, HI},
	title = {Image-to-{Image} {Translation} with {Conditional} {Adversarial} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8100115/},
	doi = {10.1109/CVPR.2017.632},
	urldate = {2024-08-28},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	month = jul,
	year = {2017},
	pages = {5967--5976},
	file = {已提交版本:C\:\\Users\\ClannXy\\Zotero\\storage\\MUCUX8KJ\\Isola 等 - 2017 - Image-to-Image Translation with Conditional Adversarial Networks.pdf:application/pdf},
}

@incollection{navab_u-net_2015,
	address = {Cham},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	volume = {9351},
	isbn = {978-3-319-24573-7 978-3-319-24574-4},
	shorttitle = {U-{Net}},
	url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
	language = {en},
	urldate = {2024-08-28},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	doi = {10.1007/978-3-319-24574-4_28},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {234--241},
	file = {全文:C\:\\Users\\ClannXy\\Zotero\\storage\\44QDU9YA\\Ronneberger 等 - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:application/pdf},
}

@article{du_medical_2020,
	title = {Medical {Image} {Segmentation} based on {U}-{Net}: {A} {Review}},
	volume = {64},
	issn = {1943-3522},
	shorttitle = {Medical {Image} {Segmentation} based on {U}-{Net}},
	url = {https://library.imaging.org/jist/articles/64/2/jist0710},
	doi = {10.2352/J.ImagingSci.Technol.2020.64.2.020508},
	number = {2},
	urldate = {2024-08-28},
	journal = {Journal of Imaging Science and Technology},
	author = {Du, Getao and Cao, Xu and Liang, Jimin and Chen, Xueli and Zhan, Yonghua},
	month = mar,
	year = {2020},
	pages = {020508--1--020508--12},
}

@inproceedings{deng_learning_2021,
	address = {Virtual Event China},
	title = {Learning {Contextual} {Transformer} {Network} for {Image} {Inpainting}},
	isbn = {978-1-4503-8651-7},
	url = {https://dl.acm.org/doi/10.1145/3474085.3475426},
	doi = {10.1145/3474085.3475426},
	language = {en},
	urldate = {2024-08-28},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Deng, Ye and Hui, Siqi and Zhou, Sanping and Meng, Deyu and Wang, Jinjun},
	month = oct,
	year = {2021},
	pages = {2529--2538},
}

@article{armanious_medgan_2020,
	title = {{MedGAN}: {Medical} image translation using {GANs}},
	volume = {79},
	issn = {08956111},
	shorttitle = {{MedGAN}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611119300990},
	doi = {10.1016/j.compmedimag.2019.101684},
	language = {en},
	urldate = {2024-08-28},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Armanious, Karim and Jiang, Chenming and Fischer, Marc and Küstner, Thomas and Hepp, Tobias and Nikolaou, Konstantin and Gatidis, Sergios and Yang, Bin},
	month = jan,
	year = {2020},
	pages = {101684},
	file = {已提交版本:C\:\\Users\\ClannXy\\Zotero\\storage\\2MVGMG2R\\Armanious 等 - 2020 - MedGAN Medical image translation using GANs.pdf:application/pdf},
}

@article{yao_pixel-wise_2018,
	title = {Pixel-wise regression using {U}-{Net} and its application on pansharpening},
	volume = {312},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231218307008},
	doi = {10.1016/j.neucom.2018.05.103},
	language = {en},
	urldate = {2024-08-28},
	journal = {Neurocomputing},
	author = {Yao, Wei and Zeng, Zhigang and Lian, Cheng and Tang, Huiming},
	month = oct,
	year = {2018},
	pages = {364--371},
}

@article{zhao_improved_2024,
	title = {A improved pooling method for convolutional neural networks},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-51258-6},
	doi = {10.1038/s41598-024-51258-6},
	abstract = {Abstract
            The pooling layer in convolutional neural networks plays a crucial role in reducing spatial dimensions, and improving computational efficiency. However, standard pooling operations such as max pooling or average pooling are not suitable for all applications and data types. Therefore, developing custom pooling layers that can adaptively learn and extract relevant features from specific datasets is of great significance. In this paper, we propose a novel approach to design and implement customizable pooling layers to enhance feature extraction capabilities in CNNs. The proposed T-Max-Avg pooling layer incorporates a threshold parameter T, which selects the K highest interacting pixels as specified, allowing it to control whether the output features of the input data are based on the maximum values or weighted averages. By learning the optimal pooling strategy during training, our custom pooling layer can effectively capture and represent discriminative information in the input data, thereby improving classification performance. Experimental results show that the proposed T-Max-Avg pooling layer achieves good performance on three different datasets. When compared to LeNet-5 model with average pooling, max pooling, and Avg-TopK methods, the T-Max-Avg pooling method achieves the highest accuracy on CIFAR-10, CIFAR-100, and MNIST datasets.},
	language = {en},
	number = {1},
	urldate = {2024-08-28},
	journal = {Scientific Reports},
	author = {Zhao, Lei and Zhang, Zhonglin},
	month = jan,
	year = {2024},
	pages = {1589},
	file = {全文:C\:\\Users\\ClannXy\\Zotero\\storage\\6LEEMV4A\\Zhao和Zhang - 2024 - A improved pooling method for convolutional neural networks.pdf:application/pdf},
}

@inproceedings{murray_generalized_2014,
	address = {Columbus, OH, USA},
	title = {Generalized {Max} {Pooling}},
	isbn = {978-1-4799-5118-5},
	url = {https://ieeexplore.ieee.org/document/6909713},
	doi = {10.1109/CVPR.2014.317},
	abstract = {State-of-the-art patch-based image representations involve a pooling operation that aggregates statistics computed from local descriptors. Standard pooling operations include sum- and max-pooling. Sum-pooling lacks discriminability because the resulting representation is strongly inﬂuenced by frequent yet often uninformative descriptors, but only weakly inﬂuenced by rare yet potentially highlyinformative ones. Max-pooling equalizes the inﬂuence of frequent and rare descriptors but is only applicable to representations that rely on count statistics, such as the bag-ofvisual-words (BOV) and its soft- and sparse-coding extensions. We propose a novel pooling mechanism that achieves the same effect as max-pooling but is applicable beyond the BOV and especially to the state-of-the-art Fisher Vector – hence the name Generalized Max Pooling (GMP). It involves equalizing the similarity between each patch and the pooled representation, which is shown to be equivalent to re-weighting the per-patch statistics. We show on ﬁve public image classiﬁcation benchmarks that the proposed GMP can lead to signiﬁcant performance gains with respect to heuristic alternatives.},
	language = {en},
	urldate = {2024-08-28},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Murray, Naila and Perronnin, Florent},
	month = jun,
	year = {2014},
	pages = {2473--2480},
	file = {PDF:C\:\\Users\\ClannXy\\Zotero\\storage\\EKJWC2DU\\Murray和Perronnin - 2014 - Generalized Max Pooling.pdf:application/pdf},
}

@article{rodriguez-martinez_replacing_2022,
	title = {Replacing pooling functions in {Convolutional} {Neural} {Networks} by linear combinations of increasing functions},
	volume = {152},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608022001605},
	doi = {10.1016/j.neunet.2022.04.028},
	language = {en},
	urldate = {2024-08-28},
	journal = {Neural Networks},
	author = {Rodriguez-Martinez, Iosu and Lafuente, Julio and Santiago, Regivan H.N. and Dimuro, Graçaliz Pereira and Herrera, Francisco and Bustince, Humberto},
	month = aug,
	year = {2022},
	pages = {380--393},
	file = {全文:C\:\\Users\\ClannXy\\Zotero\\storage\\TNLIY227\\Rodriguez-Martinez 等 - 2022 - Replacing pooling functions in Convolutional Neural Networks by linear combinations of increasing fu.pdf:application/pdf},
}

@inproceedings{pons_upsampling_2021,
	address = {Toronto, ON, Canada},
	title = {Upsampling {Artifacts} in {Neural} {Audio} {Synthesis}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72817-605-5},
	url = {https://ieeexplore.ieee.org/document/9414913/},
	doi = {10.1109/ICASSP39728.2021.9414913},
	urldate = {2024-08-28},
	booktitle = {{ICASSP} 2021 - 2021 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Pons, Jordi and Pascual, Santiago and Cengarle, Giulio and Serra, Joan},
	month = jun,
	year = {2021},
	pages = {3005--3009},
	file = {已提交版本:C\:\\Users\\ClannXy\\Zotero\\storage\\D69DGK4F\\Pons 等 - 2021 - Upsampling Artifacts in Neural Audio Synthesis.pdf:application/pdf},
}

@incollection{lian_u-net_2021,
	address = {Cham},
	title = {U-{Net} {Transformer}: {Self} and {Cross} {Attention} for {Medical} {Image} {Segmentation}},
	volume = {12966},
	isbn = {978-3-030-87588-6 978-3-030-87589-3},
	shorttitle = {U-{Net} {Transformer}},
	url = {https://link.springer.com/10.1007/978-3-030-87589-3_28},
	language = {en},
	urldate = {2024-09-01},
	booktitle = {Machine {Learning} in {Medical} {Imaging}},
	publisher = {Springer International Publishing},
	author = {Petit, Olivier and Thome, Nicolas and Rambour, Clement and Themyr, Loic and Collins, Toby and Soler, Luc},
	editor = {Lian, Chunfeng and Cao, Xiaohuan and Rekik, Islem and Xu, Xuanang and Yan, Pingkun},
	year = {2021},
	doi = {10.1007/978-3-030-87589-3_28},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {267--276},
	file = {已提交版本:C\:\\Users\\ClannXy\\Zotero\\storage\\JN5RGI7Q\\Petit 等 - 2021 - U-Net Transformer Self and Cross Attention for Medical Image Segmentation.pdf:application/pdf},
}

@inproceedings{guo_sa-unet_2021,
	address = {Milan, Italy},
	title = {{SA}-{UNet}: {Spatial} {Attention} {U}-{Net} for {Retinal} {Vessel} {Segmentation}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72818-808-9},
	shorttitle = {{SA}-{UNet}},
	url = {https://ieeexplore.ieee.org/document/9413346/},
	doi = {10.1109/ICPR48806.2021.9413346},
	urldate = {2024-09-01},
	booktitle = {2020 25th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Guo, Changlu and Szemenyei, Marton and Yi, Yugen and Wang, Wenle and Chen, Buer and Fan, Changqi},
	month = jan,
	year = {2021},
	pages = {1236--1242},
	file = {已提交版本:C\:\\Users\\ClannXy\\Zotero\\storage\\F9SXTHJF\\Guo 等 - 2021 - SA-UNet Spatial Attention U-Net for Retinal Vessel Segmentation.pdf:application/pdf},
}

@article{wang_narrowing_2024,
	title = {Narrowing the semantic gaps in {U}-{Net} with learnable skip connections: {The} case of medical image segmentation},
	volume = {178},
	issn = {08936080},
	shorttitle = {Narrowing the semantic gaps in {U}-{Net} with learnable skip connections},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608024004702},
	doi = {10.1016/j.neunet.2024.106546},
	language = {en},
	urldate = {2024-09-01},
	journal = {Neural Networks},
	author = {Wang, Haonan and Cao, Peng and Yang, Jinzhu and Zaiane, Osmar},
	month = oct,
	year = {2024},
	pages = {106546},
}
